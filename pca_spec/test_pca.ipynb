{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PCA with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99244289 0.00755711]\n",
      "[6.30061232 0.54980396]\n",
      "----------------------------\n",
      "number of features/samples in training set 2 6\n",
      "Reduced data with n_components features:  (6, 2)\n",
      "[[ 1.38340578  0.2935787 ]\n",
      " [ 2.22189802 -0.25133484]\n",
      " [ 3.6053038   0.04224385]\n",
      " [-1.38340578 -0.2935787 ]\n",
      " [-2.22189802  0.25133484]\n",
      " [-3.6053038  -0.04224385]]\n",
      "--------------------\n",
      "Principal axes in feature space,array, shape (n_components, n_features): (2, 2)\n",
      "pca.components_ [[-0.83849224 -0.54491354]\n",
      " [ 0.54491354 -0.83849224]]\n"
     ]
    }
   ],
   "source": [
    "#Test PCA with scikit-learn\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca1 = pca.fit(X)\n",
    "\n",
    "print(pca.explained_variance_ratio_) #pca.explained_variance_, that is the eigen value matrix of coviarance matrix\n",
    "print(pca.singular_values_)\n",
    "#print(X)\n",
    "print('----------------------------')\n",
    "print('number of features/samples in training set',pca.n_features_, pca.n_samples_)\n",
    "print(\"Reduced data with n_components features: \", pca.fit_transform(X).shape) # fit and transform\n",
    "print(pca.fit_transform(X))\n",
    "print('--------------------')\n",
    "print(\"Principal axes in feature space,array, shape (n_components, n_features):\",pca.components_.shape)\n",
    "print(\"pca.components_\",pca.components_)\n",
    "#res1 = np.ascontiguousarray(pca1.transform(X))\n",
    "#print(res1)\n",
    "#res2 = np.asfortranarray(res1)\n",
    "#print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PCA with my numpy implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[5.6 3.6]\n",
      " [3.6 2.4]]\n",
      "Eigenvalue:  [7.93954312 0.06045688]\n",
      "Eigenvector:  [[ 0.83849224 -0.54491354]\n",
      " [ 0.54491354  0.83849224]]\n",
      "prcentage of Eigenvalue, loss of pca compression: 0.9924428900898052\n",
      "Sonuc:  [[-1.38340578]\n",
      " [-2.22189802]\n",
      " [-3.6053038 ]\n",
      " [ 1.38340578]\n",
      " [ 2.22189802]\n",
      " [ 3.6053038 ]]\n"
     ]
    }
   ],
   "source": [
    "#my numpy implimentation\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "#X = X - X.mean(axis=0)\n",
    "cov = np.cov(X.T) #equavalent to   print(np.dot(X.T,X)/(X.shape[0]-1))\n",
    "\n",
    "print(\"Covariance matrix: \", cov)\n",
    "v, w = np.linalg.eig(cov)  #v: eigen value,shape [nfeature]  w: eigen vector. shape [nfeature,n_components]\n",
    "\n",
    "idx = v.argsort()[::-1]  # sort eigen value\n",
    "v = v[idx]\n",
    "w = w[:,idx]\n",
    "print(\"Eigenvalue: \", v)\n",
    "print(\"Eigenvector: \", w)\n",
    "print(\"prcentage of Eigenvalue, loss of pca compression:\",v[0]/v.sum())\n",
    "#retain the first k feature axis\n",
    "k=1\n",
    "print(\"Sonuc: \", X.dot(w[:, :k])) #print(\"Sonuc: \", np.dot(X, w[:, :k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PCA with my numpy+svd implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[5.6 3.6]\n",
      " [3.6 2.4]]\n",
      "(6, 1) [[ 1.38340578]\n",
      " [ 2.22189802]\n",
      " [ 3.6053038 ]\n",
      " [-1.38340578]\n",
      " [-2.22189802]\n",
      " [-3.6053038 ]]\n",
      "singular value [6.30061232 0.54980396]\n"
     ]
    }
   ],
   "source": [
    "#my numpy implimentation, use svd\n",
    "#ref <<Statistics , Data Mining , and Machine Learning in Astronomy>>\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "cov = np.cov(X.T) #equavalent to   print(np.dot(X.T,X)/(X.shape[0]-1))\n",
    "print(\"Covariance matrix: \", cov)\n",
    "\n",
    "#method 1--------------\n",
    "U, S, V = np.linalg.svd(X.T)  #v: eigen value  w: eigen vector\n",
    "k=1\n",
    "Z = np.dot(X, U[:,:k])\n",
    "print(Z.shape,Z)\n",
    "print(\"singular value\",S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[5.6 3.6]\n",
      " [3.6 2.4]]\n",
      "(6, 1) [[ 1.38340578]\n",
      " [ 2.22189802]\n",
      " [ 3.6053038 ]\n",
      " [-1.38340578]\n",
      " [-2.22189802]\n",
      " [-3.6053038 ]]\n",
      "eigen value [7.93954312 0.06045688]\n"
     ]
    }
   ],
   "source": [
    "#my numpy implimentation, use svd\n",
    "#ref <<scikit-learn 机器学习实战>>\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "cov = np.cov(X.T) #equavalent to   print(np.dot(X.T,X)/(X.shape[0]-1))\n",
    "print(\"Covariance matrix: \", cov)\n",
    "\n",
    "#method 2--------------\n",
    "U, S, V = np.linalg.svd(cov)  #v: eigen value  w: eigen vector\n",
    "k=1\n",
    "Z = np.dot(X, U[:,:k])\n",
    "print(Z.shape,Z)\n",
    "print(\"eigen value\",S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with cleaned data(recenter+rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:  [[0.15555556 0.15      ]\n",
      " [0.15       0.15      ]]\n",
      "Eigenvalue vector:  [0.3028035  0.00275206]\n",
      "Eigenvector:  [[ 0.71362292 -0.70053003]\n",
      " [ 0.70053003  0.71362292]]\n",
      "Sonuc:  [[-0.29406966]\n",
      " [-0.41300682]\n",
      " [-0.70707648]\n",
      " [ 0.29406966]\n",
      " [ 0.41300682]\n",
      " [ 0.70707648]]\n"
     ]
    }
   ],
   "source": [
    "#clean data, numpy\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "X = X - X.mean(axis=0)\n",
    "X = X / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "cov = np.cov(X.T)\n",
    "print(\"Covariance matrix: \", cov)\n",
    "v, w = np.linalg.eig(cov)  #v: eigen value  w: eigen vector\n",
    "\n",
    "idx = v.argsort()[::-1]  # sort eigen value\n",
    "v = v[idx]\n",
    "w = w[:,idx]\n",
    "print(\"Eigenvalue vector: \", v)\n",
    "print(\"Eigenvector: \", w)\n",
    "\n",
    "#retain the first k feature axis\n",
    "k=1\n",
    "print(\"Sonuc: \", X.dot(w[:, :k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1) [[ 0.29406966]\n",
      " [ 0.41300682]\n",
      " [ 0.70707648]\n",
      " [-0.29406966]\n",
      " [-0.41300682]\n",
      " [-0.70707648]]\n"
     ]
    }
   ],
   "source": [
    "#clean data, numpy+svd\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "X = X - X.mean(axis=0)\n",
    "X = X / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "U, S, V = np.linalg.svd(cov)  #v: eigen value  w: eigen vector\n",
    "k=1\n",
    "Z = np.dot(X, U[:,:k])\n",
    "print(Z.shape,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29406966]\n",
      " [ 0.41300682]\n",
      " [ 0.70707648]\n",
      " [-0.29406966]\n",
      " [-0.41300682]\n",
      " [-0.70707648]]\n"
     ]
    }
   ],
   "source": [
    "##clean data, numpy, scikit-learn\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])   #[nsamples,nfeatures]\n",
    "X = X - X.mean(axis=0)\n",
    "X = X / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca1 = pca.fit(X)\n",
    "\n",
    "print(pca1.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
